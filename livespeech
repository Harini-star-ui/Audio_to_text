import pyaudio
import queue
import json
from vosk import Model, KaldiRecognizer

def load_model():
    return Model("model")  # Ensure the model is downloaded and placed correctly

def process_audio(q, recognizer, label):
    """Processes the audio from the queue and prints recognized text."""
    while not q.empty():
        data = q.get()
        if recognizer.AcceptWaveform(data):
            result = json.loads(recognizer.Result())
            print(f"{label}: {result['text']}")

def audio_callback(q):
    """Returns a callback function for PyAudio to store audio data."""
    def callback(in_data, frame_count, time_info, status):
        q.put(in_data)
        return in_data, pyaudio.paContinue
    return callback

def run_speech_recognition():
    """Main function to run dual microphone speech recognition."""
    p = pyaudio.PyAudio()
    model = load_model()
    
    q1, q2 = queue.Queue(), queue.Queue()
    
    stream1 = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True,
                     frames_per_buffer=8000, input_device_index=0, stream_callback=audio_callback(q1))
    stream2 = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True,
                     frames_per_buffer=8000, input_device_index=1, stream_callback=audio_callback(q2))
    
    rec1, rec2 = KaldiRecognizer(model, 16000), KaldiRecognizer(model, 16000)
    
    print("Listening... Press Ctrl+C to stop.")
    
    try:
        while True:
            process_audio(q1, rec1, "Caller")
            process_audio(q2, rec2, "Receiver")
    except KeyboardInterrupt:
        print("Stopping...")
    
    stream1.stop_stream()
    stream1.close()
    stream2.stop_stream()
    stream2.close()
    p.terminate()

def main():
    run_speech_recognition()

if __name__ == "__main__":
    main()
