import wave
import json
from vosk import Model, KaldiRecognizer

def load_model():
    return Model("model")  # Ensure the model is downloaded and placed correctly

def split_audio(file_path, chunk_duration=10):
    """Splits an audio file into chunks for processing."""
    with wave.open(file_path, "rb") as wf:
        frame_rate = wf.getframerate()
        chunk_size = int(frame_rate * chunk_duration)
        
        audio_chunks = []
        while True:
            data = wf.readframes(chunk_size)
            if not data:
                break
            audio_chunks.append(data)
        
    return audio_chunks, frame_rate

def transcribe_chunks(chunks, frame_rate, model):
    """Transcribes each audio chunk using Vosk."""
    recognizer = KaldiRecognizer(model, frame_rate)
    
    transcripts = []
    for i, chunk in enumerate(chunks):
        if recognizer.AcceptWaveform(chunk):
            result = json.loads(recognizer.Result())
            transcripts.append(result["text"])
    
    return transcripts

def run_speech_recognition(file_path):
    """Main function to split and transcribe audio files."""
    model = load_model()
    chunks, frame_rate = split_audio(file_path)
    transcripts = transcribe_chunks(chunks, frame_rate, model)
    
    for i, text in enumerate(transcripts):
        print(f"Chunk {i+1}: {text}")

def main():
    file_path = "input.wav"  # Replace with your audio file
    run_speech_recognition(file_path)

if __name__ == "__main__":
    main()
