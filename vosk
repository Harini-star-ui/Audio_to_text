from vosk import Model, KaldiRecognizer
import wave
import json

# Load Vosk Model (Update with the correct path)
MODEL_PATH = "vosk-model-small-en-us-0.15"

def transcribe_audio(file_path):
    model = Model(MODEL_PATH)
    
    # Open audio file
    wf = wave.open(file_path, "rb")
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
        raise ValueError("Audio file must be WAV format with 16-bit PCM and mono channel.")

    recognizer = KaldiRecognizer(model, wf.getframerate())

    result_text = ""
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if recognizer.AcceptWaveform(data):
            result = json.loads(recognizer.Result())
            result_text += result["text"] + " "

    # Finalizing transcription
    final_result = json.loads(recognizer.FinalResult())
    result_text += final_result["text"]
    
    return result_text.strip()

# Example Usage
audio_file = "your_audio.wav"  # Ensure it's a 16-bit PCM WAV file
text = transcribe_audio(audio_file)
print("Transcribed Text:", text)
